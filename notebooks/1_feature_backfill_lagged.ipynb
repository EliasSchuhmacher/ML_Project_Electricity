{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f139ba67",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 01: Feature Backfill for Air Quality Data</span>\n",
    "\n",
    "\n",
    "## üóíÔ∏è You have the following tasks\n",
    "1. Choose an Air Quality Sensor\n",
    "2. Update the country, city, and street information to point to YOUR chosen Air Quality Sensor\n",
    "3. Download historical measures for your Air Quality Sensor as a CSV file\n",
    "4. Update the path of the CSV file in this notebook to point to the one that you downloaded\n",
    "5. Create an account on www.hopsworks.ai and get your HOPSWORKS_API_KEY\n",
    "6. Run this notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6a80c",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f447120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from functions import util\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "014f3362-87f5-4abd-bb57-bebd28638bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x5PZCK0patagTBDP.SjxqfFY5JlMcD4HCF4BEd0rDdMJVabM44KJEdZRIVrYSoxvGd8lfgz23KgblRcI9\n",
      "2025-01-08 14:08:26,669 INFO: Initializing external client\n",
      "2025-01-08 14:08:26,670 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-08 14:08:26,670 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-08 14:08:27,805 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1207495\n",
      "Project: ML_Project_Electricity\n"
     ]
    }
   ],
   "source": [
    "# If you haven't set the env variable 'HOPSWORKS_API_KEY', then uncomment the next line and enter your API key\n",
    "# os.environ[\"HOPSWORKS_API_KEY\"] = \"\"\n",
    "with open('../data/keys/hopsworks-api-key.txt', 'r') as file:\n",
    "    os.environ[\"HOPSWORKS_API_KEY\"] = file.read().rstrip()\n",
    "    print(os.environ[\"HOPSWORKS_API_KEY\"])\n",
    "# logout from hopsworks first\n",
    "project = hopsworks.login(project=\"ML_Project_Electricity\", api_key_value=os.environ[\"HOPSWORKS_API_KEY\"])\n",
    "print(f\"Project: {project.name}\")\n",
    "\n",
    "# util.purge_project(proj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a0e47",
   "metadata": {},
   "source": [
    "## LOAD ALL THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eed55a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>PriceArea</th>\n",
       "      <th>SpotPriceEUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-31 23:00:00</td>\n",
       "      <td>SE3</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-31 22:00:00</td>\n",
       "      <td>SE3</td>\n",
       "      <td>7.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-31 21:00:00</td>\n",
       "      <td>SE3</td>\n",
       "      <td>14.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-12-31 20:00:00</td>\n",
       "      <td>SE3</td>\n",
       "      <td>21.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-12-31 19:00:00</td>\n",
       "      <td>SE3</td>\n",
       "      <td>23.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time PriceArea  SpotPriceEUR\n",
       "0 2024-12-31 23:00:00       SE3          2.24\n",
       "3 2024-12-31 22:00:00       SE3          7.93\n",
       "4 2024-12-31 21:00:00       SE3         14.98\n",
       "7 2024-12-31 20:00:00       SE3         21.51\n",
       "8 2024-12-31 19:00:00       SE3         23.01"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start by loading historical electricity prices:\n",
    "# Load the Elspotprices.csv file\n",
    "csv_file = Path(\"../data/Elspotprices.csv\")\n",
    "e_df = pd.read_csv(csv_file, delimiter=\";\")\n",
    "e_df.head()\n",
    "\n",
    "# Remove HourUTC and SpotpriceDKK column\n",
    "e_df = e_df.drop(columns=['HourUTC', 'SpotPriceDKK'])\n",
    "\n",
    "# Rename HourDK to Time and make it proper datetime format\n",
    "e_df = e_df.rename(columns={\"HourDK\": \"time\"})\n",
    "e_df['time'] = pd.to_datetime(e_df['time'])\n",
    "\n",
    "# Make the Time column the index of the DataFrame\n",
    "# e_df = e_df.set_index('time')\n",
    "\n",
    "# Format SpotPriceEUR into a float\n",
    "e_df['SpotPriceEUR'] = e_df['SpotPriceEUR'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Split the DataFrame based on the 'PriceArea' column\n",
    "price_area_groups = e_df.groupby('PriceArea')\n",
    "\n",
    "# Create separate DataFrames for each PriceArea\n",
    "price_area_dfs = {price_area: group for price_area, group in price_area_groups}\n",
    "\n",
    "# Access individual DataFrames\n",
    "se3_df = price_area_dfs['SE3']\n",
    "se4_df = price_area_dfs['SE4']\n",
    "\n",
    "se3_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ba2810b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>PriceArea</th>\n",
       "      <th>SpotPriceEUR</th>\n",
       "      <th>spot_price_rolling</th>\n",
       "      <th>spot_price_rolling_3h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35087</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>SE4</td>\n",
       "      <td>2.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35085</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>SE4</td>\n",
       "      <td>1.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35083</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>SE4</td>\n",
       "      <td>0.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time PriceArea  SpotPriceEUR  spot_price_rolling  \\\n",
       "35087 2023-01-01 00:00:00       SE4          2.01                 NaN   \n",
       "35085 2023-01-01 01:00:00       SE4          1.38                 NaN   \n",
       "35083 2023-01-01 02:00:00       SE4          0.09                 NaN   \n",
       "\n",
       "       spot_price_rolling_3h  \n",
       "35087                    NaN  \n",
       "35085                    NaN  \n",
       "35083                   1.16  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a rolling mean of the last 24*4 hours to the price data\n",
    "# Sort the data by time before doing the rolling mean\n",
    "se3_df = se3_df.sort_values('time')\n",
    "se4_df = se4_df.sort_values('time')\n",
    "\n",
    "se3_df['spot_price_rolling'] = se3_df['SpotPriceEUR'].rolling(window=24*7).mean()\n",
    "se4_df['spot_price_rolling'] = se4_df['SpotPriceEUR'].rolling(window=24*7).mean()\n",
    "\n",
    "# Add a rolling mean of the last 3 hours\n",
    "se3_df['spot_price_rolling_3h'] = se3_df['SpotPriceEUR'].rolling(window=3).mean()\n",
    "se4_df['spot_price_rolling_3h'] = se4_df['SpotPriceEUR'].rolling(window=3).mean()\n",
    "\n",
    "se4_df.head(3)\n",
    "\n",
    "\n",
    "# order needs to be reversed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c167c1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87</td>\n",
       "      <td>15.3</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>14.8</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>10.4</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  temperature  precipitation  cloud_cover  \\\n",
       "0 2023-01-01 00:00:00          2.8            0.0           87   \n",
       "1 2023-01-01 01:00:00          2.4            0.0          100   \n",
       "2 2023-01-01 02:00:00          1.6            0.0          100   \n",
       "3 2023-01-01 03:00:00          0.8            0.0          100   \n",
       "4 2023-01-01 04:00:00          0.2            0.0          100   \n",
       "\n",
       "   wind_speed_10m        Date  Weekday  Month  Hour  \n",
       "0            15.3  2023-01-01        6      1     0  \n",
       "1            14.8  2023-01-01        6      1     1  \n",
       "2            11.2  2023-01-01        6      1     2  \n",
       "3            10.4  2023-01-01        6      1     3  \n",
       "4             9.7  2023-01-01        6      1     4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the weather data for Stockholm and Malmo\n",
    "\n",
    "weather_sthlm_df = pd.read_csv(\"../data/Hourly_weather_stockholm.csv\", header=2)\n",
    "weather_malmo_df = pd.read_csv(\"../data/Hourly_weather_malmo.csv\", header=2)\n",
    "\n",
    "# weather_sthlm_df.head()\n",
    "\n",
    "# Splite the 'time' column into 'Date', 'Weekday', 'Month' and 'Hour' columns\n",
    "weather_sthlm_df['time'] = pd.to_datetime(weather_sthlm_df['time'])\n",
    "weather_sthlm_df['Date'] = weather_sthlm_df['time'].dt.date\n",
    "weather_sthlm_df['Weekday'] = weather_sthlm_df['time'].dt.weekday\n",
    "weather_sthlm_df['Month'] = weather_sthlm_df['time'].dt.month\n",
    "weather_sthlm_df['Hour'] = weather_sthlm_df['time'].dt.hour\n",
    "\n",
    "weather_malmo_df['time'] = pd.to_datetime(weather_malmo_df['time'])\n",
    "weather_malmo_df['Date'] = weather_malmo_df['time'].dt.date\n",
    "weather_malmo_df['Weekday'] = weather_malmo_df['time'].dt.weekday\n",
    "weather_malmo_df['Month'] = weather_malmo_df['time'].dt.month\n",
    "weather_malmo_df['Hour'] = weather_malmo_df['time'].dt.hour\n",
    "\n",
    "weather_sthlm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a442017b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge completed.\n",
      "Merge completed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Hour</th>\n",
       "      <th>sunshine_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87</td>\n",
       "      <td>15.3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13654.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>14.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13654.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13654.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>10.4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13654.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>9.7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13654.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                time  temperature  precipitation  cloud_cover  \\\n",
       "0 2023-01-01 2023-01-01 00:00:00          2.8            0.0           87   \n",
       "1 2023-01-01 2023-01-01 01:00:00          2.4            0.0          100   \n",
       "2 2023-01-01 2023-01-01 02:00:00          1.6            0.0          100   \n",
       "3 2023-01-01 2023-01-01 03:00:00          0.8            0.0          100   \n",
       "4 2023-01-01 2023-01-01 04:00:00          0.2            0.0          100   \n",
       "\n",
       "   wind_speed_10m  Weekday  Month  Hour  sunshine_duration  \n",
       "0            15.3        6      1     0           13654.35  \n",
       "1            14.8        6      1     1           13654.35  \n",
       "2            11.2        6      1     2           13654.35  \n",
       "3            10.4        6      1     3           13654.35  \n",
       "4             9.7        6      1     4           13654.35  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the hourly weather data with daily total sunshine duration data\n",
    "\n",
    "# Load the daily sunshine duration data for SE3 (Stockholm)\n",
    "sunshine_stockholm_df = pd.read_csv(\"../data/Daily_sunshine_stockholm.csv\", header=2)\n",
    "sunshine_stockholm_df['Date'] = pd.to_datetime(sunshine_stockholm_df['time'])\n",
    "sunshine_stockholm_df = sunshine_stockholm_df.drop(columns=['time'])\n",
    "sunshine_stockholm_df = sunshine_stockholm_df.set_index('Date')\n",
    "\n",
    "# Merge the weather data (weather_sthlm_df) with the sunshine duration data (if it hasn't been done already)\n",
    "if 'sunshine_duration' not in weather_sthlm_df.columns:\n",
    "    # Merge the weather data with the sunshine duration data\n",
    "    weather_sthlm_df['Date'] = weather_sthlm_df['time'].dt.date\n",
    "    weather_sthlm_df = weather_sthlm_df.set_index('Date')\n",
    "    weather_sthlm_df = weather_sthlm_df.join(sunshine_stockholm_df, how='left')\n",
    "    weather_sthlm_df = weather_sthlm_df.reset_index()\n",
    "    print(\"Merge completed.\")\n",
    "else:\n",
    "    print(\"Merge has already been done.\")\n",
    "\n",
    "weather_sthlm_df.head()\n",
    "\n",
    "# Load the daily sunshine duration data for SE4 (Malm√∂)\n",
    "sunshine_malmo_df = pd.read_csv(\"../data/Daily_sunshine_malmo.csv\", header=2)\n",
    "sunshine_malmo_df['Date'] = pd.to_datetime(sunshine_malmo_df['time'])\n",
    "sunshine_malmo_df = sunshine_malmo_df.drop(columns=['time'])\n",
    "sunshine_malmo_df = sunshine_malmo_df.set_index('Date')\n",
    "\n",
    "# sunshine_malmo_df.head()\n",
    "\n",
    "# Merge the weather data with the sunshine duration data (if it hasn't been done already)\n",
    "if 'sunshine_duration' not in weather_malmo_df.columns:\n",
    "    # Merge the weather data with the sunshine duration data\n",
    "    weather_malmo_df['Date'] = weather_malmo_df['time'].dt.date\n",
    "    weather_malmo_df = weather_malmo_df.set_index('Date')\n",
    "    weather_malmo_df = weather_malmo_df.join(sunshine_malmo_df, how='left')\n",
    "    weather_malmo_df = weather_malmo_df.reset_index()\n",
    "    print(\"Merge completed.\")\n",
    "else:\n",
    "    print(\"Merge has already been done.\")\n",
    "\n",
    "weather_sthlm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81520d0d",
   "metadata": {},
   "source": [
    "## DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c036ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with missing values\n",
    "weather_sthlm_df = weather_sthlm_df.dropna()\n",
    "weather_malmo_df = weather_malmo_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1856cfe",
   "metadata": {},
   "source": [
    "## Create feature groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfc05369",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = project.get_feature_store()\n",
    "\n",
    "# Create a feature group for the electricity prices in SE3\n",
    "se3_fg = fs.get_or_create_feature_group(\n",
    "    name=\"se3_electricity_prices\", \n",
    "    version=1, \n",
    "    description=\"Electricity prices in SE3\",\n",
    "    primary_key=[\"time\"],\n",
    "    event_time=\"time\")\n",
    "\n",
    "# Create a feature group for the electricity prices in SE4\n",
    "se4_fg = fs.get_or_create_feature_group(\n",
    "    name=\"se4_electricity_prices\", \n",
    "    version=1, \n",
    "    description=\"Electricity prices in SE4\",\n",
    "    primary_key=[\"time\"],\n",
    "    event_time=\"time\")\n",
    "\n",
    "# Create a feature group for the weather data in Stockholm\n",
    "sthlm_fg = fs.get_or_create_feature_group(\n",
    "    name=\"stockholm_weather\", \n",
    "    version=1, \n",
    "    description=\"Weather data in Stockholm\",\n",
    "    primary_key=[\"time\"],\n",
    "    event_time=\"time\")\n",
    "\n",
    "# # Create a feature group for the weather data in Malm√∂\n",
    "malmo_fg = fs.get_or_create_feature_group(\n",
    "    name=\"malmo_weather\", \n",
    "    version=1, \n",
    "    description=\"Weather data in Malm√∂\",\n",
    "    primary_key=[\"time\"],\n",
    "    event_time=\"time\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef1d22f",
   "metadata": {},
   "source": [
    "## Insert Historical data into feature groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f17657de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1207495/fs/1195127/fg/1393774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 17544/17544 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: se3_electricity_prices_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1207495/jobs/named/se3_electricity_prices_1_offline_fg_materialization/executions\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1207495/fs/1195127/fg/1393775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 17544/17544 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: se4_electricity_prices_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1207495/jobs/named/se4_electricity_prices_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('se4_electricity_prices_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Insert data into the feature groups\n",
    "se3_fg.insert(se3_df)\n",
    "se4_fg.insert(se4_df)\n",
    "# sthlm_fg.insert(weather_sthlm_df)\n",
    "# malmo_fg.insert(weather_malmo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c706e751",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 5: Read your CSV file into a DataFrame </span>\n",
    "\n",
    "The cell below will read up historical air quality data as a CSV file into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc3a1212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>o3</th>\n",
       "      <th>so2</th>\n",
       "      <th>co</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-02</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>2015-06-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>2015-01-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>2015-01-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3472 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  pm25    o3  so2   co\n",
       "0    2024-11-01  15.0  27.0  NaN  1.0\n",
       "1    2024-11-02  22.0  19.0  NaN  NaN\n",
       "2    2024-11-03  23.0  22.0  NaN  NaN\n",
       "3    2024-11-04  18.0  23.0  NaN  NaN\n",
       "4    2024-11-05  17.0  19.0  NaN  NaN\n",
       "...         ...   ...   ...  ...  ...\n",
       "3467 2015-06-29   NaN  42.0  1.0  1.0\n",
       "3468 2015-06-30   NaN  33.0  2.0  1.0\n",
       "3469 2015-01-15   NaN  11.0  NaN  1.0\n",
       "3470 2015-01-26   NaN  15.0  NaN  1.0\n",
       "3471 2015-01-27   NaN  24.0  1.0  1.0\n",
       "\n",
       "[3472 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(csv_file,  parse_dates=['date'], skipinitialspace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812eb37-04e3-4291-8d77-a69ef7a195bc",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 6: Data cleaning + BONUS: add 3 day rolling mean of pm25</span>\n",
    "\n",
    "\n",
    "### Rename columns if needed and drop unneccessary columns\n",
    "\n",
    "We want to have a DataFrame with 2 columns - `date` and `pm25` after this cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcfa73",
   "metadata": {},
   "source": [
    "## Check the data types for the columns in your DataFrame\n",
    "\n",
    " * `date` should be of type   datetime64[ns] \n",
    " * `pm25` should be of type float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd20c859-ef3c-4b54-bbcb-83898afefa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>rolling_mean_pm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-02</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>2015-06-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>2015-01-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>2015-01-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3472 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  pm25  rolling_mean_pm25\n",
       "0    2024-11-01  15.0          15.000000\n",
       "1    2024-11-02  22.0          18.500000\n",
       "2    2024-11-03  23.0          20.000000\n",
       "3    2024-11-04  18.0          21.000000\n",
       "4    2024-11-05  17.0          19.333333\n",
       "...         ...   ...                ...\n",
       "3467 2015-06-29   NaN                NaN\n",
       "3468 2015-06-30   NaN                NaN\n",
       "3469 2015-01-15   NaN                NaN\n",
       "3470 2015-01-26   NaN                NaN\n",
       "3471 2015-01-27   NaN                NaN\n",
       "\n",
       "[3472 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These commands will succeed if your CSV file didn't have a `median` or `timestamp` column\n",
    "df = df.rename(columns={\"median\": \"pm25\"})\n",
    "df = df.rename(columns={\"timestamp\": \"date\"})\n",
    "\n",
    "df_aq = df[['date', 'pm25']]\n",
    "\n",
    "# Set the index to the 'date' column\n",
    "# df_aq.set_index('date', inplace=True)\n",
    "\n",
    "df_aq['pm25'] = df_aq['pm25'].astype('float32')\n",
    "\n",
    "# Compute the rolling mean of the last 3 days, allowing for NaN values\n",
    "df_aq['rolling_mean_pm25'] = df_aq['pm25'].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "df_aq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f13a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3472 entries, 0 to 3471\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   date               3472 non-null   datetime64[ns]\n",
      " 1   pm25               3367 non-null   float32       \n",
      " 2   rolling_mean_pm25  3369 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float32(1), float64(1)\n",
      "memory usage: 67.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Cast the pm25 column to be a float32 data type\n",
    "df_aq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19911f73",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 7: Drop any rows with missing data </span>\n",
    "It will make the model training easier if there is no missing data in the rows, so we drop any rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37b0a762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>rolling_mean_pm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-02</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3362</th>\n",
       "      <td>2015-03-27</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363</th>\n",
       "      <td>2015-03-28</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3364</th>\n",
       "      <td>2015-03-29</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3365</th>\n",
       "      <td>2015-03-30</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3366</th>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3367 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  pm25  rolling_mean_pm25\n",
       "0    2024-11-01  15.0          15.000000\n",
       "1    2024-11-02  22.0          18.500000\n",
       "2    2024-11-03  23.0          20.000000\n",
       "3    2024-11-04  18.0          21.000000\n",
       "4    2024-11-05  17.0          19.333333\n",
       "...         ...   ...                ...\n",
       "3362 2015-03-27  21.0          36.000000\n",
       "3363 2015-03-28  28.0          26.666667\n",
       "3364 2015-03-29  34.0          27.666667\n",
       "3365 2015-03-30  26.0          29.333333\n",
       "3366 2015-03-31  31.0          30.333333\n",
       "\n",
       "[3367 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aq.dropna(inplace=True)\n",
    "df_aq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f089c159",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 8: Add country, city, street, url to the DataFrame </span>\n",
    "\n",
    "Your CSV file may have many other air quality measurement columns. We will only work with the `pm25` column.\n",
    "\n",
    "We add the columns for the country, city, and street names that you changed for your Air Quality sensor.\n",
    "\n",
    "We also want to make sure the `pm25` column is a float32 data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15d3cc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>rolling_mean_pm25</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>bondville</td>\n",
       "      <td>bondville-illinois-usa</td>\n",
       "      <td>https://api.waqi.info/feed/@7638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-02</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>usa</td>\n",
       "      <td>bondville</td>\n",
       "      <td>bondville-illinois-usa</td>\n",
       "      <td>https://api.waqi.info/feed/@7638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>bondville</td>\n",
       "      <td>bondville-illinois-usa</td>\n",
       "      <td>https://api.waqi.info/feed/@7638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>bondville</td>\n",
       "      <td>bondville-illinois-usa</td>\n",
       "      <td>https://api.waqi.info/feed/@7638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>usa</td>\n",
       "      <td>bondville</td>\n",
       "      <td>bondville-illinois-usa</td>\n",
       "      <td>https://api.waqi.info/feed/@7638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3362</th>\n",
       "      <td>2015-03-27</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>usa</td>\n",
       "      <td>bondville</td>\n",
       "      <td>bondville-illinois-usa</td>\n",
       "      <td>https://api.waqi.info/feed/@7638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363</th>\n",
       "      <td>2015-03-28</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>usa</td>\n",
       "      <td>bondville</td>\n",
       "      <td>bondville-illinois-usa</td>\n",
       "      <td>https://api.waqi.info/feed/@7638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3364</th>\n",
       "      <td>2015-03-29</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>usa</td>\n",
       "      <td>bondville</td>\n",
       "      <td>bondville-illinois-usa</td>\n",
       "      <td>https://api.waqi.info/feed/@7638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3365</th>\n",
       "      <td>2015-03-30</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>usa</td>\n",
       "      <td>bondville</td>\n",
       "      <td>bondville-illinois-usa</td>\n",
       "      <td>https://api.waqi.info/feed/@7638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3366</th>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>usa</td>\n",
       "      <td>bondville</td>\n",
       "      <td>bondville-illinois-usa</td>\n",
       "      <td>https://api.waqi.info/feed/@7638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3367 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  pm25  rolling_mean_pm25 country       city  \\\n",
       "0    2024-11-01  15.0          15.000000     usa  bondville   \n",
       "1    2024-11-02  22.0          18.500000     usa  bondville   \n",
       "2    2024-11-03  23.0          20.000000     usa  bondville   \n",
       "3    2024-11-04  18.0          21.000000     usa  bondville   \n",
       "4    2024-11-05  17.0          19.333333     usa  bondville   \n",
       "...         ...   ...                ...     ...        ...   \n",
       "3362 2015-03-27  21.0          36.000000     usa  bondville   \n",
       "3363 2015-03-28  28.0          26.666667     usa  bondville   \n",
       "3364 2015-03-29  34.0          27.666667     usa  bondville   \n",
       "3365 2015-03-30  26.0          29.333333     usa  bondville   \n",
       "3366 2015-03-31  31.0          30.333333     usa  bondville   \n",
       "\n",
       "                      street                               url  \n",
       "0     bondville-illinois-usa  https://api.waqi.info/feed/@7638  \n",
       "1     bondville-illinois-usa  https://api.waqi.info/feed/@7638  \n",
       "2     bondville-illinois-usa  https://api.waqi.info/feed/@7638  \n",
       "3     bondville-illinois-usa  https://api.waqi.info/feed/@7638  \n",
       "4     bondville-illinois-usa  https://api.waqi.info/feed/@7638  \n",
       "...                      ...                               ...  \n",
       "3362  bondville-illinois-usa  https://api.waqi.info/feed/@7638  \n",
       "3363  bondville-illinois-usa  https://api.waqi.info/feed/@7638  \n",
       "3364  bondville-illinois-usa  https://api.waqi.info/feed/@7638  \n",
       "3365  bondville-illinois-usa  https://api.waqi.info/feed/@7638  \n",
       "3366  bondville-illinois-usa  https://api.waqi.info/feed/@7638  \n",
       "\n",
       "[3367 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your sensor may have columns we won't use, so only keep the date and pm25 columns\n",
    "# If the column names in your DataFrame are different, rename your columns to `date` and `pm25`\n",
    "df_aq['country']=country\n",
    "df_aq['city']=city\n",
    "df_aq['street']=street\n",
    "df_aq['url']=aqicn_url\n",
    "df_aq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e8276",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055befa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Loading Weather Data from [Open Meteo](https://open-meteo.com/en/docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78686a28",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 9: Download the Historical Weather Data </span>\n",
    "\n",
    "https://open-meteo.com/en/docs/historical-weather-api#hourly=&daily=temperature_2m_mean,precipitation_sum,wind_speed_10m_max,wind_direction_10m_dominant\n",
    "\n",
    "We will download the historical weather data for your `city` by first extracting the earliest date from your DataFrame containing the historical air quality measurements.\n",
    "\n",
    "We will download all daily historical weather data measurements for your `city` from the earliest date in your air quality measurement DataFrame. It doesn't matter if there are missing days of air quality measurements. We can store all of the daily weather measurements, and when we build our training dataset, we will join up the air quality measurements for a given day to its weather features for that day. \n",
    "\n",
    "The weather features we will download are:\n",
    "\n",
    " * `temperature (average over the day)`\n",
    " * `precipitation (the total over the day)`\n",
    " * `wind speed (average over the day)`\n",
    " * `wind direction (the most dominant direction over the day)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96d604b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 40.105445861816406¬∞N -88.361328125¬∞E\n",
      "Elevation 221.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n"
     ]
    }
   ],
   "source": [
    "earliest_aq_date = pd.Series.min(df_aq['date'])\n",
    "earliest_aq_date = earliest_aq_date.strftime('%Y-%m-%d')\n",
    "earliest_aq_date\n",
    "\n",
    "weather_df = util.get_historical_weather(city, earliest_aq_date, str(today), latitude, longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd6eefe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3576 entries, 0 to 3575\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   date                         3576 non-null   datetime64[ns]\n",
      " 1   temperature_2m_mean          3576 non-null   float32       \n",
      " 2   precipitation_sum            3576 non-null   float32       \n",
      " 3   wind_speed_10m_max           3576 non-null   float32       \n",
      " 4   wind_direction_10m_dominant  3576 non-null   float32       \n",
      " 5   city                         3576 non-null   object        \n",
      "dtypes: datetime64[ns](1), float32(4), object(1)\n",
      "memory usage: 139.7+ KB\n"
     ]
    }
   ],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d5eeb",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 10: Define Data Validation Rules </span>\n",
    "\n",
    "We will validate the air quality measurements (`pm25` values) before we write them to Hopsworks.\n",
    "\n",
    "We define a data validation rule (an expectation in Great Expectations) that ensures that `pm25` values are not negative or above the max value available by the sensor.\n",
    "\n",
    "We will attach this expectation to the air quality feature group, so that we validate the `pm25` data every time we write a DataFrame to the feature group. We want to prevent garbage-in, garbage-out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11bcdcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"expectation_type\": \"expect_column_min_to_be_between\", \"kwargs\": {\"column\": \"pm25\", \"min_value\": -0.1, \"max_value\": 500.0, \"strict_min\": true}, \"meta\": {}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import great_expectations as ge\n",
    "aq_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"aq_expectation_suite\"\n",
    ")\n",
    "\n",
    "aq_expectation_suite.add_expectation(\n",
    "    ge.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_min_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":\"pm25\",\n",
    "            \"min_value\":-0.1,\n",
    "            \"max_value\":500.0,\n",
    "            \"strict_min\":True\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bef9ed3",
   "metadata": {},
   "source": [
    "## Expectations for Weather Data\n",
    "Here, we define an expectation for 2 columns in our weather DataFrame - `precipitation_sum` and `wind_speed_10m_max`, where we expect both values to be greater than zero, but less than 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bff8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "weather_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"weather_expectation_suite\"\n",
    ")\n",
    "\n",
    "def expect_greater_than_zero(col):\n",
    "    weather_expectation_suite.add_expectation(\n",
    "        ge.core.ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_min_to_be_between\",\n",
    "            kwargs={\n",
    "                \"column\":col,\n",
    "                \"min_value\":-0.1,\n",
    "                \"max_value\":1000.0,\n",
    "                \"strict_min\":True\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "expect_greater_than_zero(\"precipitation_sum\")\n",
    "expect_greater_than_zero(\"wind_speed_10m_max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3830b7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291a502",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ STEP 11: Connect to Hopsworks and save the sensor country, city, street names as a secret</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aeaf20ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd82f7",
   "metadata": {},
   "source": [
    "#### Save country, city, street names as a secret\n",
    "\n",
    "These will be downloaded from Hopsworks later in the (1) daily feature pipeline and (2) the daily batch inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd36749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENSOR_LOCATION_JSON already exists. To update, delete the secret in the UI (https://c.app.hopsworks.ai/account/secrets) and re-run this cell.\n",
      "{\"country\": \"usa\", \"city\": \"bondville\", \"street\": \"bondville-illinois-usa\", \"aqicn_url\": \"https://api.waqi.info/feed/@7638\", \"latitude\": 40.11, \"longitude\": -88.37}\n"
     ]
    }
   ],
   "source": [
    "dict_obj = {\n",
    "    \"country\": country,\n",
    "    \"city\": city,\n",
    "    \"street\": street,\n",
    "    \"aqicn_url\": aqicn_url,\n",
    "    \"latitude\": latitude,\n",
    "    \"longitude\": longitude\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a JSON string\n",
    "str_dict = json.dumps(dict_obj)\n",
    "\n",
    "try:\n",
    "    secrets.create_secret(\"SENSOR_LOCATION_JSON\", str_dict)\n",
    "except hopsworks.RestAPIError:\n",
    "    print(\"SENSOR_LOCATION_JSON already exists. To update, delete the secret in the UI (https://c.app.hopsworks.ai/account/secrets) and re-run this cell.\")\n",
    "    existing_key = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "    print(f\"{existing_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e79b3f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ STEP 12: Create the Feature Groups and insert the DataFrames in them </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3755b6f",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üå´ Air Quality Data\n",
    "    \n",
    " 1. Provide a name, description, and version for the feature group.\n",
    " 2. Define the `primary_key`: we have to select which columns uniquely identify each row in the DataFrame - by providing them as the `primary_key`. Here, each air quality sensor measurement is uniquely identified by `country`, `street`, and  `date`.\n",
    " 3. Define the `event_time`: We also define which column stores the timestamp or date for the row - `date`.\n",
    " 4. Attach any `expectation_suite` containing data validation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d2bb403",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "air_quality_fg = fs.get_or_create_feature_group(\n",
    "    name='air_quality_new',\n",
    "    description='Air Quality characteristics of each day, with rolling mean of pm25',\n",
    "    version=1,\n",
    "    primary_key=['city', 'street', 'date'],\n",
    "    event_time=\"date\",\n",
    "    expectation_suite=aq_expectation_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2933cfa5",
   "metadata": {},
   "source": [
    "#### Insert the DataFrame into the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fb42574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1161369/fs/1152072/fg/1347992\n",
      "2024-11-14 18:34:41,086 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1161369/fs/1152072/fg/1347992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951fb59bdcab46fa86abb49e970b60e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/3367 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_new_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1161369/jobs/named/air_quality_new_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x15af0a770>,\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pm25\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 500.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 671795\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 3.0,\n",
       "         \"element_count\": 3367,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-11-14T05:34:41.000086Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 1,\n",
       "     \"successful_expectations\": 1,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"aq_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2024-11-14T18:34:41.086416+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"baa05fe4-a2ae-11ef-9555-fe175aafa5a8\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20241114T173441.086316Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_quality_fg.insert(df_aq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a1606",
   "metadata": {},
   "source": [
    "#### Enter a description for each feature in the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "577effca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x15afc60b0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_quality_fg.update_feature_description(\"date\", \"Date of measurement of air quality\")\n",
    "air_quality_fg.update_feature_description(\"country\", \"Country where the air quality was measured (sometimes a city in acqcn.org)\")\n",
    "air_quality_fg.update_feature_description(\"city\", \"City where the air quality was measured\")\n",
    "air_quality_fg.update_feature_description(\"street\", \"Street in the city where the air quality was measured\")\n",
    "air_quality_fg.update_feature_description(\"pm25\", \"Particles less than 2.5 micrometers in diameter (fine particles) pose health risk\")\n",
    "air_quality_fg.update_feature_description(\"rolling_mean_pm25\", \"Rolling mean of pm25 over the last 3 days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894b731",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üå¶ Weather Data\n",
    "    \n",
    " 1. Provide a name, description, and version for the feature group.\n",
    " 2. Define the `primary_key`: we have to select which columns uniquely identify each row in the DataFrame - by providing them as the `primary_key`. Here, each weather measurement is uniquely identified by `city` and  `date`.\n",
    " 3. Define the `event_time`: We also define which column stores the timestamp or date for the row - `date`.\n",
    " 4. Attach any `expectation_suite` containing data validation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "572a84ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create feature group \n",
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name='weather',\n",
    "    description='Weather characteristics of each day',\n",
    "    version=1,\n",
    "    primary_key=['city', 'date'],\n",
    "    event_time=\"date\",\n",
    "    expectation_suite=weather_expectation_suite\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721881b7",
   "metadata": {},
   "source": [
    "#### Insert the DataFrame into the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ba846ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1161369/fs/1152072/fg/1342814\n",
      "2024-11-08 18:36:47,575 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1161369/fs/1152072/fg/1342814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c961a33d31fe4e4aa91628c3507b3c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/3570 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1161369/jobs/named/weather_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x166765ed0>,\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"wind_speed_10m_max\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 666640\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 6.193674087524414,\n",
       "         \"element_count\": 3570,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-11-08T05:36:47.000575Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"precipitation_sum\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 666639\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 0.0,\n",
       "         \"element_count\": 3570,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-11-08T05:36:47.000575Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 2,\n",
       "     \"successful_expectations\": 2,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"weather_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2024-11-08T18:36:47.575097+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"078a9074-9df8-11ef-a52d-fe175aafa5a8\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20241108T173647.575032Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert data\n",
    "weather_fg.insert(weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87422d",
   "metadata": {},
   "source": [
    "#### Enter a description for each feature in the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71e6f6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x1665f3100>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_fg.update_feature_description(\"date\", \"Date of measurement of weather\")\n",
    "weather_fg.update_feature_description(\"city\", \"City where weather is measured/forecast for\")\n",
    "weather_fg.update_feature_description(\"temperature_2m_mean\", \"Temperature in Celsius\")\n",
    "weather_fg.update_feature_description(\"precipitation_sum\", \"Precipitation (rain/snow) in mm\")\n",
    "weather_fg.update_feature_description(\"wind_speed_10m_max\", \"Wind speed at 10m abouve ground\")\n",
    "weather_fg.update_feature_description(\"wind_direction_10m_dominant\", \"Dominant Wind direction over the dayd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc16b5",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 02: Daily Feature Pipeline \n",
    " </span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c029117",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Exercises:** \n",
    " </span> \n",
    "\n",
    "Extra Homework:\n",
    "\n",
    "  * Try adding a new feature based on a rolling window of 3 days for 'pm25'\n",
    "      * This is not easy, as forecasting more than 1 day in the future, you won't have the previous 3 days of pm25 measurements.\n",
    "      * df.set_index(\"date\").rolling(3).mean() is only the start....\n",
    "  * Parameterize the notebook, so that you can provide the `country`/`street`/`city`/`url`/`csv_file` as parameters. \n",
    "      * Hint: this will also require making the secret name (`SENSOR_LOCATION_JSON`), e.g., add the street name as part of the secret name. Then you have to pass that secret name as a parameter when running the operational feature pipeline and batch inference pipelines.\n",
    "      * After you have done this, collect the street/city/url/csv files for all the sensors in your city or region and you make dashboards for all of the air quality sensors in your city/region. You could even then add a dashboard for your city/region, as done [here for Poland](https://github.com/erno98/ID2223).\n",
    "\n",
    "Improve this AI System\n",
    "  * As of mid 2024, there is no API call available to download historical data from the AQIN website. You could improve this system by writing a PR to download the CSV file using Python Selenium and the URL for the sensor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb407899",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
